{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Desktop/Speed_Dating_Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = pd.DataFrame(df['match'])\n",
    "data_X = df.drop(['match','decision','decision_o','Unnamed: 0'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change gender into binary\n",
    "def gender(value): \n",
    "    if value == 'female': \n",
    "        return 0 \n",
    "    else: \n",
    "        return 1\n",
    "male = data_X['gender'].map(gender)\n",
    "data_X['gender'] = male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_d_age(value): \n",
    "    if value == '[2-3]': \n",
    "        return 2\n",
    "    if value == '[4-6]': \n",
    "        return 3\n",
    "    if value == '[0-1]': \n",
    "        return 1\n",
    "    if value == '[7-37]': \n",
    "        return 4\n",
    "dage = data_X['d_d_age'].map(d_d_age)\n",
    "data_X['d_d_age'] = dage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race(value): \n",
    "    if value == 'asian/pacific islander/asian-american': \n",
    "        return 1\n",
    "    if value == 'black/african american': \n",
    "        return 2\n",
    "    if value == 'european/caucasian-american': \n",
    "        return 3\n",
    "    if value =='latino/hispanic american': \n",
    "        return 4\n",
    "    else: \n",
    "        return 5\n",
    "racee = data_X['race'].map(race)\n",
    "data_X['race'] = racee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_o =data_X['race_o'].map(race)\n",
    "data_X['race_o'] = race_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "study1 = list(data_X['field'].value_counts().index)\n",
    "def study(value): \n",
    "    if value in study1: \n",
    "        return study1.index(value)\n",
    "study_idx = data_X['field'].map(study)\n",
    "data_X['field'] = study_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>...</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  age_o  d_age  d_d_age  race  race_o  samerace  \\\n",
       "0       0  21.0   27.0      6        3     1       3         0   \n",
       "1       0  21.0   22.0      1        1     1       3         0   \n",
       "2       0  21.0   22.0      1        1     1       1         1   \n",
       "3       0  21.0   23.0      2        2     1       3         0   \n",
       "4       0  21.0   24.0      3        2     1       4         0   \n",
       "\n",
       "   importance_same_race  importance_same_religion ...   concerts  music  \\\n",
       "0                   2.0                       4.0 ...       10.0    9.0   \n",
       "1                   2.0                       4.0 ...       10.0    9.0   \n",
       "2                   2.0                       4.0 ...       10.0    9.0   \n",
       "3                   2.0                       4.0 ...       10.0    9.0   \n",
       "4                   2.0                       4.0 ...       10.0    9.0   \n",
       "\n",
       "   shopping  yoga  interests_correlate  expected_happy_with_sd_people  \\\n",
       "0       8.0   1.0                 0.14                            3.0   \n",
       "1       8.0   1.0                 0.54                            3.0   \n",
       "2       8.0   1.0                 0.16                            3.0   \n",
       "3       8.0   1.0                 0.61                            3.0   \n",
       "4       8.0   1.0                 0.21                            3.0   \n",
       "\n",
       "   expected_num_matches  like  guess_prob_liked  met  \n",
       "0                   4.0   7.0               6.0  0.0  \n",
       "1                   4.0   7.0               5.0  1.0  \n",
       "2                   4.0   7.0               0.0  1.0  \n",
       "3                   4.0   7.0               6.0  0.0  \n",
       "4                   4.0   6.0               6.0  0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under - Sampling to deal with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X2 = data_X.copy()\n",
    "data_X2['match'] = match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first you need to select the ones from majority class and pick it at random\n",
    "no_match = len(data_X2[data_X2['match'] == 0])\n",
    "no_match_indices = data_X2[data_X2.match == 0].index\n",
    "random_indices = np.random.choice(no_match_indices,no_match, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matched indices and then concatenate to get final\n",
    "match_indices = data_X2[data_X2.match == 1].index\n",
    "under_sample_indices = np.concatenate([match_indices,random_indices])\n",
    "under_sample = data_X2.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under = under_sample.loc[:,under_sample.columns != 'match']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'match']\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "clf = clf.fit(X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is: 0.8008921330089214\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_under_test)\n",
    "print('Accuracy on test data is:',(accuracy_score(y_under_test,preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      " [[1810  257]\n",
      " [ 234  165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      2067\n",
      "           1       0.39      0.41      0.40       399\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      2466\n",
      "   macro avg       0.64      0.64      0.64      2466\n",
      "weighted avg       0.81      0.80      0.80      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The confusion matrix is:\\n',confusion_matrix(y_under_test,preds))\n",
    "print(classification_report(y_under_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(data_X, match,\n",
    "                                                  test_size = .1,\n",
    "                                                  random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=None,\n",
       "            oob_score=False, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      " [[667  38]\n",
      " [ 62  55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       705\n",
      "           1       0.59      0.47      0.52       117\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       822\n",
      "   macro avg       0.75      0.71      0.73       822\n",
      "weighted avg       0.87      0.88      0.87       822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the result that we would get on the validation set\n",
    "print('The confusion matrix is:\\n',confusion_matrix(y_val,clf_rf.predict(x_val)))\n",
    "print(classification_report(y_val, clf_rf.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      " [[6830   40]\n",
      " [  63 1287]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6870\n",
      "           1       0.97      0.95      0.96      1350\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8220\n",
      "   macro avg       0.98      0.97      0.98      8220\n",
      "weighted avg       0.99      0.99      0.99      8220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the result that we would get on the test set which is the entire dataset \n",
    "print('The confusion matrix is:\\n',confusion_matrix(match,clf_rf.predict(data_X)))\n",
    "print(classification_report(match, clf_rf.predict(data_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 83.91727493917274\n"
     ]
    }
   ],
   "source": [
    "#Creating the standard scaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# creating svc. Here we use the default instead of linear as mentioned on the piazza post. \n",
    "svc_clf = SVC()\n",
    "\n",
    "# Creating the pipeline\n",
    "pipe = Pipeline(steps=[('sca',scaler ), ('svc', svc_clf)])\n",
    "\n",
    "#Pass the pipeline in to a cross_val_score \n",
    "scores = cross_val_score(pipe, data_X, match, cv=5)\n",
    "\n",
    "#printing the average accuracy\n",
    "print('Average Accuracy:',scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__kernel': 'linear'}\n",
      "Average Accuracy: 83.43065693430655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# for the 'svm' part of the pipeline, tune the 'kernel' hyperparameter\n",
    "param_grid = {'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# your code goes here\n",
    "grid_search = GridSearchCV(pipe,param_grid,cv = 5,scoring ='accuracy')\n",
    "grid_search.fit(data_X,match)\n",
    "\n",
    "#printing out the best params\n",
    "print(grid_search.best_params_)\n",
    "scores = cross_val_score(grid_search, data_X,match, cv =5)\n",
    "print('Average Accuracy:',scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92      6870\n",
      "           1       0.77      0.09      0.16      1350\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      8220\n",
      "   macro avg       0.81      0.54      0.54      8220\n",
      "weighted avg       0.84      0.85      0.79      8220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(match, grid_search.predict(data_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE( kind='svm' )\n",
    "X_smote, Y_smote = smote.fit_sample( data_X, match )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 83.50800582241631\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# creating svc. Here we use the default instead of linear as mentioned on the piazza post. \n",
    "svc_clf = SVC()\n",
    "\n",
    "# Creating the pipeline\n",
    "pipe = Pipeline(steps=[('sca',scaler ), ('svc', svc_clf)])\n",
    "\n",
    "#Pass the pipeline in to a cross_val_score \n",
    "scores = cross_val_score(pipe, X_smote, Y_smote, cv=5)\n",
    "\n",
    "#printing the average accuracy\n",
    "print('Average Accuracy:',scores.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.5474452554744526\n",
      "Accuracy with 10-fold cross validation: 75.77858880778588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_X, match, test_size=0.20, random_state=None)\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = .8)\n",
    "X_train_res, Y_train_res = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "\n",
    "#create NB clf and fit it\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train_res, Y_train_res)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "#predict the accuracy with one model\n",
    "print(\"Accuracy is \", accuracy_score(y_val,y_pred))\n",
    "\n",
    "#cross validation\n",
    "scores = cross_val_score(clf, data_X, match, cv=10)                                         \n",
    "print(\"Accuracy with 10-fold cross validation:\", scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      " [[1193  204]\n",
      " [ 218   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      1397\n",
      "           1       0.12      0.12      0.12       247\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1644\n",
      "   macro avg       0.48      0.49      0.49      1644\n",
      "weighted avg       0.74      0.74      0.74      1644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The confusion matrix is:\\n',confusion_matrix(y_val,clf_rf.predict(x_val)))\n",
    "print(classification_report(y_val, clf_rf.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darwin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from amb_sdk.sdk import DarwinSdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DarwinSdk()\n",
    "ds.set_url('https://amb-demo-api.sparkcognition.com/v1/')\n",
    "status, msg = ds.auth_login_user('aifazg92@gmail.com', 'UcLUQHr5N7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Desktop/Speed_Dating_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Set your user id and password accordingly\n",
    "USER=\"aifazg92@gmail.com\"\n",
    "PW=\"UcLUQHr5N7\"\n",
    "\n",
    "path = 'Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>[4-6]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>latino/hispanic american</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gender   age  age_o  d_age d_d_age  \\\n",
       "0           0  female  21.0   27.0      6   [4-6]   \n",
       "1           1  female  21.0   22.0      1   [0-1]   \n",
       "2           2  female  21.0   22.0      1   [0-1]   \n",
       "3           3  female  21.0   23.0      2   [2-3]   \n",
       "4           4  female  21.0   24.0      3   [2-3]   \n",
       "\n",
       "                                    race  \\\n",
       "0  asian/pacific islander/asian-american   \n",
       "1  asian/pacific islander/asian-american   \n",
       "2  asian/pacific islander/asian-american   \n",
       "3  asian/pacific islander/asian-american   \n",
       "4  asian/pacific islander/asian-american   \n",
       "\n",
       "                                  race_o  samerace  importance_same_race  \\\n",
       "0            european/caucasian-american         0                   2.0   \n",
       "1            european/caucasian-american         0                   2.0   \n",
       "2  asian/pacific islander/asian-american         1                   2.0   \n",
       "3            european/caucasian-american         0                   2.0   \n",
       "4               latino/hispanic american         0                   2.0   \n",
       "\n",
       "   ...    yoga interests_correlate  expected_happy_with_sd_people  \\\n",
       "0  ...     1.0                0.14                            3.0   \n",
       "1  ...     1.0                0.54                            3.0   \n",
       "2  ...     1.0                0.16                            3.0   \n",
       "3  ...     1.0                0.61                            3.0   \n",
       "4  ...     1.0                0.21                            3.0   \n",
       "\n",
       "   expected_num_matches  like  guess_prob_liked  met  decision  decision_o  \\\n",
       "0                   4.0   7.0               6.0  0.0         1           0   \n",
       "1                   4.0   7.0               5.0  1.0         1           0   \n",
       "2                   4.0   7.0               0.0  1.0         1           1   \n",
       "3                   4.0   7.0               6.0  0.0         1           1   \n",
       "4                   4.0   6.0               6.0  0.0         1           1   \n",
       "\n",
       "   match  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'Speed_Dating_Clean.csv'\n",
    "df = pd.read_csv(os.path.join(path, dataset_name))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: BAD REQUEST - {\"message\": \"Dataset already exists\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset\n",
    "status, dataset = ds.upload_dataset(os.path.join(path, dataset_name))\n",
    "if not status:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Taken', 'starttime': '2019-04-10T20:58:18.565433', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': ['113327899a904380b18b4c860f7b6b5b'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Complete', 'starttime': '2019-04-10T20:58:18.565433', 'endtime': '2019-04-10T20:58:29.361292', 'percent_complete': 100, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': ['113327899a904380b18b4c860f7b6b5b'], 'model_name': None, 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "# clean dataset\n",
    "target = \"match\"\n",
    "status, job_id = ds.clean_data(dataset_name, target = target)\n",
    "\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Requested', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': None}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 5, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 1, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 10, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 10, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 10, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 10, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 10, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 10, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': None, 'percent_complete': 10, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-10T20:59:30.708917', 'endtime': '2019-04-10T21:01:42.288745', 'percent_complete': 100, 'job_type': 'TrainModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': None, 'model_name': 'match_model0', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "model = target + \"_model0\"\n",
    "status, job_id = ds.create_model(dataset_names = dataset_name, \\\n",
    "                                 model_name =  model, \\\n",
    "                                 max_train_time = '00:02')\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-10T21:03:22.771644', 'endtime': None, 'percent_complete': 0, 'job_type': 'AnalyzeModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': None, 'artifact_names': ['4e1c8d80e30144ddb53a283939767191'], 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-10T21:03:22.771644', 'endtime': '2019-04-10T21:03:24.738266', 'percent_complete': 100, 'job_type': 'AnalyzeModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': None, 'artifact_names': ['4e1c8d80e30144ddb53a283939767191'], 'model_name': 'match_model0', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve feature importance of built model\n",
    "status, artifact = ds.analyze_model(model)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(artifact['job_name'])\n",
    "else:\n",
    "    print(artifact)\n",
    "status, feature_importance = ds.download_artifact(artifact['artifact_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decision = 1                0.159841\n",
       "decision_o = 1              0.138219\n",
       "attractive_o                0.037845\n",
       "like                        0.036113\n",
       "shared_interests_o          0.030024\n",
       "shared_interests_partner    0.025967\n",
       "funny_o                     0.025851\n",
       "attractive_partner          0.022149\n",
       "funny_partner               0.021650\n",
       "guess_prob_liked            0.019298\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-10T21:04:05.814755', 'endtime': None, 'percent_complete': 0, 'job_type': 'RunModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': ['f61e156cd289480c99bb95a96a1379d0'], 'model_name': 'match_model0', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-10T21:04:05.814755', 'endtime': '2019-04-10T21:04:15.608287', 'percent_complete': 100, 'job_type': 'RunModel', 'loss': 0.3134501576423645, 'generations': 2, 'dataset_names': ['Speed_Dating_Clean.csv'], 'artifact_names': ['f61e156cd289480c99bb95a96a1379d0'], 'model_name': 'match_model0', 'job_error': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'Job completed')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status, artifact = ds.run_model(dataset_name, model)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match    prob_0    prob_1\n",
       "0      0  0.999942  0.000058\n",
       "1      0  0.999921  0.000079\n",
       "2      1  0.000029  0.999971\n",
       "3      1  0.000028  0.999972\n",
       "4      1  0.000043  0.999957"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6870\n",
      "           1       1.00      1.00      1.00      1350\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      8220\n",
      "   macro avg       1.00      1.00      1.00      8220\n",
      "weighted avg       1.00      1.00      1.00      8220\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(df[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(classification_report(df[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer 1': {'type': 'LinearGene', 'parameters': {'activation': 'relu', 'numunits': 288}}}, {'layer 2': {'type': 'LinearGene', 'parameters': {'activation': 'relu', 'numunits': 2}}}]\n"
     ]
    }
   ],
   "source": [
    "status, model_type = ds.lookup_model_name(model)\n",
    "print(model_type['description']['best_genome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
