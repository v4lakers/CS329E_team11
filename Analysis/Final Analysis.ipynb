{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "ts = '{:%Y%m%d%H%M%S}'.format(datetime.datetime.now())\n",
    "\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from amb_sdk.sdk import DarwinSdk\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8220, 287)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>same_race_i</th>\n",
       "      <th>same_religion_i</th>\n",
       "      <th>attractive_o_i</th>\n",
       "      <th>sincere_o_i</th>\n",
       "      <th>intelligence_o_i</th>\n",
       "      <th>funny_o_i</th>\n",
       "      <th>ambitious_o_i</th>\n",
       "      <th>shared_interests_o_i</th>\n",
       "      <th>...</th>\n",
       "      <th>field_tc [health ed]</th>\n",
       "      <th>field_teaching of english</th>\n",
       "      <th>field_tesol</th>\n",
       "      <th>field_theater</th>\n",
       "      <th>field_theatre management &amp; producing</th>\n",
       "      <th>field_theory</th>\n",
       "      <th>field_undergrad - gs</th>\n",
       "      <th>field_urban planning</th>\n",
       "      <th>field_working</th>\n",
       "      <th>field_writing: literary nonfiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  age_o  same_race_i  same_religion_i  attractive_o_i  sincere_o_i  \\\n",
       "0  21.0   27.0          2.0              4.0            0.35         0.20   \n",
       "1  21.0   22.0          2.0              4.0            0.60         0.00   \n",
       "2  21.0   22.0          2.0              4.0            0.19         0.18   \n",
       "3  21.0   23.0          2.0              4.0            0.30         0.05   \n",
       "4  21.0   24.0          2.0              4.0            0.30         0.10   \n",
       "\n",
       "   intelligence_o_i  funny_o_i  ambitious_o_i  shared_interests_o_i  \\\n",
       "0              0.20       0.20           0.00                  0.05   \n",
       "1              0.00       0.40           0.00                  0.00   \n",
       "2              0.19       0.18           0.14                  0.12   \n",
       "3              0.15       0.40           0.05                  0.05   \n",
       "4              0.20       0.10           0.10                  0.20   \n",
       "\n",
       "                  ...                  field_tc [health ed]  \\\n",
       "0                 ...                                     0   \n",
       "1                 ...                                     0   \n",
       "2                 ...                                     0   \n",
       "3                 ...                                     0   \n",
       "4                 ...                                     0   \n",
       "\n",
       "   field_teaching of english  field_tesol  field_theater  \\\n",
       "0                          0            0              0   \n",
       "1                          0            0              0   \n",
       "2                          0            0              0   \n",
       "3                          0            0              0   \n",
       "4                          0            0              0   \n",
       "\n",
       "   field_theatre management & producing  field_theory  field_undergrad - gs  \\\n",
       "0                                     0             0                     0   \n",
       "1                                     0             0                     0   \n",
       "2                                     0             0                     0   \n",
       "3                                     0             0                     0   \n",
       "4                                     0             0                     0   \n",
       "\n",
       "   field_urban planning  field_working  field_writing: literary nonfiction  \n",
       "0                     0              0                                   0  \n",
       "1                     0              0                                   0  \n",
       "2                     0              0                                   0  \n",
       "3                     0              0                                   0  \n",
       "4                     0              0                                   0  \n",
       "\n",
       "[5 rows x 287 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Data/speed-dating_raw.csv\")\n",
    "x = ['gender', 'race', 'race_o', 'field']\n",
    "columns = list(data)\n",
    "\n",
    "# Deleting Bins\n",
    "for column in columns:\n",
    "    if column not in x and data[str(column)].dtype.name == 'object':\n",
    "        del data[str(column)]\n",
    "\n",
    "# Deleting useless columns        \n",
    "del data['has_null']\n",
    "del data['wave']\n",
    "del data['d_age']\n",
    "del data['samerace']\n",
    "del data['expected_happy_with_sd_people']\n",
    "del data['expected_num_interested_in_me']\n",
    "del data['expected_num_matches']\n",
    "del data['like']\n",
    "del data['guess_prob_liked']\n",
    "del data['decision']\n",
    "del data['decision_o']\n",
    "\n",
    "# Replace age NA with mean\n",
    "mean = round(data['age'].mean())\n",
    "data['age'].fillna(mean, inplace = True)\n",
    "mean = round(data['age_o'].mean())\n",
    "data['age_o'].fillna(mean, inplace = True)\n",
    "\n",
    "# Make sure difference in age is correct\n",
    "data['age_d'] = (data['age'] - data['age_o'])\n",
    "data['age_d_abs'] = data['age_d'].abs()\n",
    "\n",
    "# Replace race NA with other\n",
    "data['race'].fillna('other', inplace= True)\n",
    "data['race_o'].fillna('other', inplace = True)\n",
    "\n",
    "# Verifying that same_race is correct with replaced race\n",
    "data['same_race'] = (data['race'] == data['race_o'])\n",
    "\n",
    "# Replace NA with 0 for preferences\n",
    "preferences = ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']          \n",
    "for pref in preferences:\n",
    "    data[pref].fillna(0, inplace = True)\n",
    "\n",
    "# Renaming column names\n",
    "data.rename(columns = {'importance_same_race':'same_race_i',\n",
    "                       'importance_same_religion': 'same_religion_i',\n",
    "                       'pref_o_attractive':'attractive_o_i',\n",
    "                       'pref_o_sincere':'sincere_o_i',\n",
    "                       'pref_o_intelligence':'intelligence_o_i',\n",
    "                       'pref_o_funny':'funny_o_i',\n",
    "                       'pref_o_ambitious':'ambitious_o_i',\n",
    "                       'pref_o_shared_interests':'shared_interests_o_i',\n",
    "                       'attractive_important':'attractive_i',\n",
    "                       'sincere_important': 'sincere_i',\n",
    "                       'intellicence_important': 'intelligence_i',\n",
    "                       'funny_important':'funny_i',\n",
    "                       'ambtition_important':'ambitious_i',\n",
    "                       'shared_interests_important':'shared_interests_i',\n",
    "                       'ambition':'ambitious',\n",
    "                       'sinsere_o': 'sincere_o',\n",
    "                       'ambitous_o':'ambitious_o',\n",
    "                       'ambition_partner':'ambitious_partner'}, inplace = True)\n",
    "\n",
    "# Making sure that importance columns add up to 100\n",
    "data['o_i'] = data['attractive_o_i'] + data['sincere_o_i'] + data['intelligence_o_i'] + data['funny_o_i'] + data['ambitious_o_i'] + data['shared_interests_o_i']\n",
    "data['attractive_o_i'] = (data['attractive_o_i'] / data['o_i'])\n",
    "data['sincere_o_i'] = (data['sincere_o_i'] / data['o_i'])\n",
    "data['intelligence_o_i'] = (data['intelligence_o_i'] / data['o_i'])\n",
    "data['funny_o_i'] = (data['funny_o_i'] / data['o_i'])\n",
    "data['ambitious_o_i'] = (data['ambitious_o_i'] / data['o_i'])\n",
    "data['shared_interests_o_i'] = (data['shared_interests_o_i'] / data['o_i'])\n",
    "\n",
    "data['i'] = data['attractive_i'] + data['sincere_i'] + data['intelligence_i'] + data['funny_i'] + data['ambitious_i'] + data['shared_interests_i']\n",
    "data['attractive_i'] = (data['attractive_i'] / data['i'])\n",
    "data['sincere_i'] = (data['sincere_i'] / data['i'])\n",
    "data['intelligence_i'] = (data['intelligence_i'] / data['i'])\n",
    "data['funny_i'] = (data['funny_i'] / data['i'])\n",
    "data['ambitious_i'] = (data['ambitious_i'] / data['i'])\n",
    "data['shared_interests_i'] = (data['shared_interests_i'] / data['i'])\n",
    "\n",
    "del data['o_i']\n",
    "del data['i']\n",
    "\n",
    "# Filling in data that are empty\n",
    "temp = ['attractive_o_i', 'sincere_o_i', 'intelligence_o_i', 'funny_o_i', 'ambitious_o_i', 'shared_interests_o_i', 'attractive_i', 'sincere_i', 'intelligence_i', 'funny_i', 'ambitious_i', 'shared_interests_i']          \n",
    "for t in temp:\n",
    "    data[t].fillna((1.0 / 6.0), inplace = True)\n",
    "\n",
    "# Replacing same_race_i & same_religion_i with mean\n",
    "mean = data['same_race_i'].mean()\n",
    "data['same_race_i'].fillna(round(mean), inplace = True)\n",
    "\n",
    "mean = data['same_religion_i'].mean()\n",
    "data['same_religion_i'].fillna(round(mean), inplace = True)\n",
    "\n",
    "# One Hot Encoding\n",
    "data = pd.concat([data, pd.get_dummies(data['gender'], prefix = 'gender')], axis = 1)\n",
    "data = pd.concat([data, pd.get_dummies(data['race'], prefix = 'race')], axis = 1)\n",
    "data = pd.concat([data, pd.get_dummies(data['race_o'], prefix = 'race_o')], axis = 1)\n",
    "data = pd.concat([data, pd.get_dummies(data['field'], prefix = 'field')], axis = 1)\n",
    "\n",
    "del data['gender']\n",
    "del data['race']\n",
    "del data['race_o']\n",
    "del data['field']\n",
    "\n",
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "data['same_race'] = le.fit_transform(data['same_race'])\n",
    "\n",
    "# Fill NA's with mean\n",
    "mean = data['attractive_o'].mean()\n",
    "data['attractive_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['sincere_o'].mean()\n",
    "data['sincere_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['intelligence_o'].mean()\n",
    "data['intelligence_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['funny_o'].mean()\n",
    "data['funny_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['ambitious_o'].mean()\n",
    "data['ambitious_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['shared_interests_o'].mean()\n",
    "data['shared_interests_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['attractive'].mean()\n",
    "data['attractive'].fillna(round(mean), inplace = True)\n",
    "mean = data['sincere'].mean()\n",
    "data['sincere'].fillna(round(mean), inplace = True)\n",
    "mean = data['intelligence'].mean()\n",
    "data['intelligence'].fillna(round(mean), inplace = True)\n",
    "mean = data['funny'].mean()\n",
    "data['funny'].fillna(round(mean), inplace = True)\n",
    "mean = data['ambitious'].mean()\n",
    "data['ambitious'].fillna(round(mean), inplace = True)\n",
    "mean = data['attractive_partner'].mean()\n",
    "data['attractive_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['sincere_partner'].mean()\n",
    "data['sincere_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['intelligence_partner'].mean()\n",
    "data['intelligence_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['funny_partner'].mean()\n",
    "data['funny_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['ambitious_partner'].mean()\n",
    "data['ambitious_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['shared_interests_partner'].mean()\n",
    "data['shared_interests_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['met'].mean()\n",
    "data['met'].fillna(round(mean), inplace = True)\n",
    "\n",
    "# Delete rows with NA's for interests correlate\n",
    "data = data.dropna(axis = 0, subset = ['interests_correlate'])\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13740, 286)\n",
      "(13740,)\n"
     ]
    }
   ],
   "source": [
    "data_copy = data\n",
    "data_Y = data_copy['match']\n",
    "data_X = data_copy.drop(['match'], axis = 1)\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 'minority')\n",
    "smote_X, smote_Y = sm.fit_sample(data_X, data_Y)\n",
    "\n",
    "print(smote_X.shape)\n",
    "print(smote_Y.shape)\n",
    "smote_X = DataFrame(smote_X, columns = data_X.columns)\n",
    "smote_Y = Series(smote_Y, name = 'match')\n",
    "data = pd.concat([smote_X, smote_Y], axis = 1)\n",
    "data.head()\n",
    "\n",
    "data.to_csv('Speed_Dating_Clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13740, 286)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>same_race_i</th>\n",
       "      <th>same_religion_i</th>\n",
       "      <th>attractive_o_i</th>\n",
       "      <th>sincere_o_i</th>\n",
       "      <th>intelligence_o_i</th>\n",
       "      <th>funny_o_i</th>\n",
       "      <th>ambitious_o_i</th>\n",
       "      <th>shared_interests_o_i</th>\n",
       "      <th>...</th>\n",
       "      <th>field_tc [health ed]</th>\n",
       "      <th>field_teaching of english</th>\n",
       "      <th>field_tesol</th>\n",
       "      <th>field_theater</th>\n",
       "      <th>field_theatre management &amp; producing</th>\n",
       "      <th>field_theory</th>\n",
       "      <th>field_undergrad - gs</th>\n",
       "      <th>field_urban planning</th>\n",
       "      <th>field_working</th>\n",
       "      <th>field_writing: literary nonfiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  age_o  same_race_i  same_religion_i  attractive_o_i  sincere_o_i  \\\n",
       "0  21.0   27.0          2.0              4.0            0.35         0.20   \n",
       "1  21.0   22.0          2.0              4.0            0.60         0.00   \n",
       "2  21.0   22.0          2.0              4.0            0.19         0.18   \n",
       "3  21.0   23.0          2.0              4.0            0.30         0.05   \n",
       "4  21.0   24.0          2.0              4.0            0.30         0.10   \n",
       "\n",
       "   intelligence_o_i  funny_o_i  ambitious_o_i  shared_interests_o_i  \\\n",
       "0              0.20       0.20           0.00                  0.05   \n",
       "1              0.00       0.40           0.00                  0.00   \n",
       "2              0.19       0.18           0.14                  0.12   \n",
       "3              0.15       0.40           0.05                  0.05   \n",
       "4              0.20       0.10           0.10                  0.20   \n",
       "\n",
       "                  ...                  field_tc [health ed]  \\\n",
       "0                 ...                                   0.0   \n",
       "1                 ...                                   0.0   \n",
       "2                 ...                                   0.0   \n",
       "3                 ...                                   0.0   \n",
       "4                 ...                                   0.0   \n",
       "\n",
       "   field_teaching of english  field_tesol  field_theater  \\\n",
       "0                        0.0          0.0            0.0   \n",
       "1                        0.0          0.0            0.0   \n",
       "2                        0.0          0.0            0.0   \n",
       "3                        0.0          0.0            0.0   \n",
       "4                        0.0          0.0            0.0   \n",
       "\n",
       "   field_theatre management & producing  field_theory  field_undergrad - gs  \\\n",
       "0                                   0.0           0.0                   0.0   \n",
       "1                                   0.0           0.0                   0.0   \n",
       "2                                   0.0           0.0                   0.0   \n",
       "3                                   0.0           0.0                   0.0   \n",
       "4                                   0.0           0.0                   0.0   \n",
       "\n",
       "   field_urban planning  field_working  field_writing: literary nonfiction  \n",
       "0                   0.0            0.0                                 0.0  \n",
       "1                   0.0            0.0                                 0.0  \n",
       "2                   0.0            0.0                                 0.0  \n",
       "3                   0.0            0.0                                 0.0  \n",
       "4                   0.0            0.0                                 0.0  \n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y = data['match']\n",
    "data_X = data.drop(['match'], axis = 1)\n",
    "print(data_X.shape)\n",
    "data_X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = StandardScaler().fit_transform(data_X)\n",
    "\n",
    "pca = PCA(0.95)\n",
    "pca_X = pca.fit_transform(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13740, 234)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080140</td>\n",
       "      <td>0.448233</td>\n",
       "      <td>0.494691</td>\n",
       "      <td>-3.761400</td>\n",
       "      <td>-2.814237</td>\n",
       "      <td>0.804044</td>\n",
       "      <td>0.465357</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>-0.399509</td>\n",
       "      <td>0.365404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156988</td>\n",
       "      <td>-1.178416</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>-0.448598</td>\n",
       "      <td>-0.430335</td>\n",
       "      <td>-0.652650</td>\n",
       "      <td>0.485292</td>\n",
       "      <td>-0.127141</td>\n",
       "      <td>0.810934</td>\n",
       "      <td>0.453341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.746024</td>\n",
       "      <td>-0.216072</td>\n",
       "      <td>-0.312979</td>\n",
       "      <td>-4.650605</td>\n",
       "      <td>-3.186895</td>\n",
       "      <td>0.909309</td>\n",
       "      <td>1.370074</td>\n",
       "      <td>1.059597</td>\n",
       "      <td>-1.042069</td>\n",
       "      <td>1.121485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.845577</td>\n",
       "      <td>-0.939525</td>\n",
       "      <td>-1.791157</td>\n",
       "      <td>1.782628</td>\n",
       "      <td>-0.372270</td>\n",
       "      <td>0.224847</td>\n",
       "      <td>1.525000</td>\n",
       "      <td>1.317544</td>\n",
       "      <td>1.983727</td>\n",
       "      <td>0.684671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.442522</td>\n",
       "      <td>-2.703964</td>\n",
       "      <td>-0.922161</td>\n",
       "      <td>-2.934378</td>\n",
       "      <td>-4.239209</td>\n",
       "      <td>-0.386319</td>\n",
       "      <td>-0.190687</td>\n",
       "      <td>-0.422419</td>\n",
       "      <td>1.533997</td>\n",
       "      <td>-0.491614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661426</td>\n",
       "      <td>0.117330</td>\n",
       "      <td>-0.837959</td>\n",
       "      <td>1.133739</td>\n",
       "      <td>0.845606</td>\n",
       "      <td>0.875591</td>\n",
       "      <td>-0.427985</td>\n",
       "      <td>0.187360</td>\n",
       "      <td>0.547344</td>\n",
       "      <td>0.827998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.197814</td>\n",
       "      <td>-0.749901</td>\n",
       "      <td>-0.313529</td>\n",
       "      <td>-3.631189</td>\n",
       "      <td>-3.203978</td>\n",
       "      <td>0.489273</td>\n",
       "      <td>0.799443</td>\n",
       "      <td>0.430955</td>\n",
       "      <td>-0.177497</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024812</td>\n",
       "      <td>-1.713644</td>\n",
       "      <td>-1.630116</td>\n",
       "      <td>0.870336</td>\n",
       "      <td>-0.725677</td>\n",
       "      <td>-1.004685</td>\n",
       "      <td>1.896075</td>\n",
       "      <td>-0.385753</td>\n",
       "      <td>0.326999</td>\n",
       "      <td>0.996398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740412</td>\n",
       "      <td>0.456389</td>\n",
       "      <td>0.778752</td>\n",
       "      <td>-2.480459</td>\n",
       "      <td>-3.354329</td>\n",
       "      <td>0.196792</td>\n",
       "      <td>-0.227965</td>\n",
       "      <td>-0.116450</td>\n",
       "      <td>0.130112</td>\n",
       "      <td>-0.818731</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.362877</td>\n",
       "      <td>-1.045173</td>\n",
       "      <td>-0.644730</td>\n",
       "      <td>1.051525</td>\n",
       "      <td>-1.471961</td>\n",
       "      <td>0.192777</td>\n",
       "      <td>0.323514</td>\n",
       "      <td>-0.197241</td>\n",
       "      <td>0.406910</td>\n",
       "      <td>1.140018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.080140  0.448233  0.494691 -3.761400 -2.814237  0.804044  0.465357   \n",
       "1 -0.746024 -0.216072 -0.312979 -4.650605 -3.186895  0.909309  1.370074   \n",
       "2  0.442522 -2.703964 -0.922161 -2.934378 -4.239209 -0.386319 -0.190687   \n",
       "3 -0.197814 -0.749901 -0.313529 -3.631189 -3.203978  0.489273  0.799443   \n",
       "4  0.740412  0.456389  0.778752 -2.480459 -3.354329  0.196792 -0.227965   \n",
       "\n",
       "        7         8         9      ...          224       225       226  \\\n",
       "0 -0.215916 -0.399509  0.365404    ...     0.156988 -1.178416  0.005001   \n",
       "1  1.059597 -1.042069  1.121485    ...    -0.845577 -0.939525 -1.791157   \n",
       "2 -0.422419  1.533997 -0.491614    ...     0.661426  0.117330 -0.837959   \n",
       "3  0.430955 -0.177497  0.925532    ...    -0.024812 -1.713644 -1.630116   \n",
       "4 -0.116450  0.130112 -0.818731    ...    -1.362877 -1.045173 -0.644730   \n",
       "\n",
       "        227       228       229       230       231       232       233  \n",
       "0 -0.448598 -0.430335 -0.652650  0.485292 -0.127141  0.810934  0.453341  \n",
       "1  1.782628 -0.372270  0.224847  1.525000  1.317544  1.983727  0.684671  \n",
       "2  1.133739  0.845606  0.875591 -0.427985  0.187360  0.547344  0.827998  \n",
       "3  0.870336 -0.725677 -1.004685  1.896075 -0.385753  0.326999  0.996398  \n",
       "4  1.051525 -1.471961  0.192777  0.323514 -0.197241  0.406910  1.140018  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pca_X.shape)\n",
    "pd.DataFrame(pca_X).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Desired Parameters\n",
    "params = {\"criterion\" : ['gini', 'entropy'],\n",
    "          \"max_depth\": [5, 10, 15, 20],\n",
    "          \"max_features\": ['sqrt', 'log2'],\n",
    "          \"min_samples_leaf\": [5, 10, 15, 20]\n",
    "         }\n",
    "\n",
    "# Test Parameters\n",
    "grid_search = GridSearchCV(clf, params, cv = 10, scoring = 'accuracy')\n",
    "grid_search.fit(pca_X, data_Y)\n",
    "\n",
    "# Print Results\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(data_Y, grid_search.predict(pca_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Desired Parameters\n",
    "params = {\"criterion\" : ['gini', 'entropy'],\n",
    "          \"max_depth\": [5, 10, 15, 20],\n",
    "          \"max_features\": ['sqrt', 'log2'],\n",
    "          \"min_samples_leaf\": [5, 10, 15, 20]\n",
    "         }\n",
    "\n",
    "# Test Parameters\n",
    "grid_search = GridSearchCV(clf, params, cv = 10, scoring = 'accuracy')\n",
    "grid_search.fit(pca_X, data_Y)\n",
    "\n",
    "# Print Results\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(data_Y, grid_search.predict(pca_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Creating svc. Here we use the default instead of linear as mentioned on the piazza post. \n",
    "svc_clf = SVC()\n",
    "\n",
    "# Creating the pipeline\n",
    "pipe = Pipeline(steps = [('sca', scaler ), ('svc', svc_clf)])\n",
    "\n",
    "# Pass the pipeline in to a cross_val_score \n",
    "scores = cross_val_score(pipe, data_X, data_Y)\n",
    "\n",
    "# Printing the average accuracy\n",
    "print('Average Accuracy:', scores.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data_X, data_Y, test_size = 0.20)\n",
    "\n",
    "# Create NB clf and fit it\n",
    "clf_rf = GaussianNB()\n",
    "clf_rf.fit(train_X, train_Y)\n",
    "pred_Y = clf_rf.predict(test_X)\n",
    "\n",
    "# Predict the accuracy with one model\n",
    "print(\"Accuracy is \", accuracy_score(test_Y, pred_Y))\n",
    "\n",
    "# Cross validation\n",
    "scores = cross_val_score(clf_rf, data_X, data_Y, cv = 10)                                         \n",
    "print(\"Accuracy with 10-fold cross validation:\", scores.mean() * 100)\n",
    "\n",
    "print('The confusion matrix is:\\n', confusion_matrix(test_Y, clf_rf.predict(test_X)))\n",
    "print(classification_report(test_Y, clf_rf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier()\n",
    "pipe = Pipeline(steps = [('scaler', scaler), ('clf', clf)])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (60,), (70,), (80,), (90,), (100,)],\n",
    "    'clf__activation': ['identity', 'logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, iid = False, cv = 5)\n",
    "\n",
    "grid_search.fit(data_X, data_Y)\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_ * 100)\n",
    "\n",
    "nested_score = cross_val_score(grid_search, data_X, data_Y, cv = 5)\n",
    "print(\"Accuracy:\", nested_score.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DarwinSdk()\n",
    "ds.set_url('https://amb-demo-api.sparkcognition.com/v1/')\n",
    "status, msg = ds.auth_login_user('aifazg92@gmail.com', 'UcLUQHr5N7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Speed_Dating_Clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lookup_dataset()\n",
    "# ds.delete_dataset(\"Speed_Dating_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset to Darwin\n",
    "status, dataset = ds.upload_dataset(\"Speed_Dating_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data on Darwin\n",
    "target = \"match\"\n",
    "status, job_id = ds.clean_data(dataset_name, target = target)\n",
    "\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Darwin model\n",
    "model = target + \"_model\" + ts\n",
    "status, job_id = ds.create_model(dataset_names = dataset_name,\n",
    "                                 model_name = model,\n",
    "                                 max_train_time = '00:05')\n",
    "\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model decided by Darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.analyze_model(model)\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(artifact['job_name'])\n",
    "else:\n",
    "    print(artifact)\n",
    "status, feature_importance = ds.download_artifact(artifact['artifact_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance[:20].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(dataset_name, model)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])\n",
    "\n",
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "print(\"/n\", prediction.head())\n",
    "\n",
    "plt.plot(data[target], prediction[target], '.')\n",
    "plt.plot([0,2.3e7],[0,2.3e7],'--k')\n",
    "print('/nR^2 : ', r2_score(data[target], prediction[target]))\n",
    "\n",
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(data[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(\"/n\", classification_report(data[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, model_type = ds.lookup_model_name(model)\n",
    "print(model_type['description']['best_genome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.analyze_model(model, model_type = 'DeepNeuralNetwork')\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(artifact['job_name'])\n",
    "else:\n",
    "    print(artifact)\n",
    "status, feature_importance = ds.download_artifact(artifact['artifact_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance[:20].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(dataset_name, model, model_type = 'DeepNeuralNetwork')\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])\n",
    "\n",
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "print(\"/n\", prediction.head())\n",
    "\n",
    "plt.plot(data[target], prediction[target], '.')\n",
    "plt.plot([0,2.3e7],[0,2.3e7],'--k')\n",
    "print('/nR^2 : ', r2_score(data[target], prediction[target]))\n",
    "\n",
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(data[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(\"/n\", classification_report(data[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.analyze_model(model, model_type = 'RandomForest')\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(artifact['job_name'])\n",
    "else:\n",
    "    print(artifact)\n",
    "status, feature_importance = ds.download_artifact(artifact['artifact_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance[:20].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(dataset_name, model, model_type = 'RandomForest')\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])\n",
    "\n",
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "print(\"/n\", prediction.head())\n",
    "\n",
    "plt.plot(data[target], prediction[target], '.')\n",
    "plt.plot([0,2.3e7],[0,2.3e7],'--k')\n",
    "print('/nR^2 : ', r2_score(data[target], prediction[target]))\n",
    "\n",
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(data[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(\"/n\", classification_report(data[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status, artifact = ds.analyze_model(model, model_type = 'GradientBoosted')\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(artifact['job_name'])\n",
    "else:\n",
    "    print(artifact)\n",
    "status, feature_importance = ds.download_artifact(artifact['artifact_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance[:20].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(dataset_name, model, model_type = 'GradientBoosted')\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])\n",
    "\n",
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "print(\"/n\", prediction.head())\n",
    "\n",
    "plt.plot(data[target], prediction[target], '.')\n",
    "plt.plot([0,2.3e7],[0,2.3e7],'--k')\n",
    "print('/nR^2 : ', r2_score(data[target], prediction[target]))\n",
    "\n",
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(data[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(\"/n\", classification_report(data[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
