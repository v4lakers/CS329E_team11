{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Speed_Dating_Clean.csv\")\n",
    "match = pd.DataFrame(df['match'])\n",
    "data_X = df.drop(['match','decision','decision_o','Unnamed: 0'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X2 = data_X.copy()\n",
    "data_X2['match'] = match \n",
    "no_match = len(data_X2[data_X2['match'] == 0])\n",
    "no_match_indices = data_X2[data_X2.match == 0].index\n",
    "random_indices = np.random.choice(no_match_indices,no_match, replace=False)\n",
    "match_indices = data_X2[data_X2.match == 1].index\n",
    "under_sample_indices = np.concatenate([match_indices,random_indices])\n",
    "under_sample = data_X2.loc[under_sample_indices]\n",
    "X_under = under_sample.loc[:,under_sample.columns != 'match']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features = under_sample.iloc[:,0:63]\n",
    "label = under_sample['match']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Features \n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation and n_neighbors.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a PCA\n",
    "pca = PCA()\n",
    "\n",
    "#create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#create a pipeline that does a PCA and a KNN\n",
    "pipe = Pipeline(steps=[('pca', pca), ('knn', knn)])\n",
    "\n",
    "#Set up the parameters you want to tune for each of your pipeline steps\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 64)), #find how many principal componenet to keep\n",
    "    'knn__n_neighbors': list(range(1, 30)),  #find the best value of k\n",
    "}\n",
    "\n",
    "# your code goes here:\n",
    "# pass the pipeline and the parameters into a GridSearchCV with a 5-fold cross validation\n",
    "# call fit() on the GridSearchCV and pass in the normalized data (X_values, Y_values)\n",
    "# print out the best_score_ and best_params_ from the GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, iid=False)\n",
    "grid_search.fit(normalized_features, label)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation and n_neighbors.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a PCA\n",
    "pca = PCA()\n",
    "\n",
    "#create a KNN classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "#create a pipeline that does a PCA and a KNN\n",
    "pipe = Pipeline(steps=[('pca', pca), ('clf', clf)])\n",
    "\n",
    "#Set up the parameters you want to tune for each of your pipeline steps\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 64)), \n",
    "    \"clf__criterion\" : ['gini', 'entropy'],\n",
    "    \"clf__max_depth\": [5,10,15,20], \n",
    "    \"clf__min_samples_leaf\": [5,10,15,20]\n",
    "}\n",
    "\n",
    "# your code goes here:\n",
    "# pass the pipeline and the parameters into a GridSearchCV with a 5-fold cross validation\n",
    "# call fit() on the GridSearchCV and pass in the normalized data (X_values, Y_values)\n",
    "# print out the best_score_ and best_params_ from the GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, iid=False)\n",
    "grid_search.fit(features, label)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "# Desired Parameters\n",
    "params = {\"criterion\" : ['gini', 'entropy'],\n",
    "          \"max_depth\": [5,10,15,20], \n",
    "         \"min_samples_leaf\": [5,10,15,20],\n",
    "         \"max_features\": [5,10,15,20]}\n",
    "\n",
    "# Test Parameters\n",
    "grid_search = GridSearchCV(clf, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, label)\n",
    "\n",
    "# Print Results\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features = under_sample.iloc[:,0:63]\n",
    "label = under_sample['match']\n",
    "\n",
    "\n",
    "# Normalize Features \n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "# Desired Parameters\n",
    "x = list(range(1, 31))\n",
    "params = {\"n_neighbors\": x}\n",
    "\n",
    "# Test Parameters\n",
    "grid_search = GridSearchCV(neigh, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(normalized_features, label)\n",
    "\n",
    "# Print Results\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Speed_Dating_Clean.csv\")\n",
    "match = pd.DataFrame(df['match'])\n",
    "data_X = df.drop(['match','decision','decision_o','Unnamed: 0'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X2 = data_X.copy()\n",
    "data_X2['match'] = match \n",
    "no_match = len(data_X2[data_X2['match'] == 0])\n",
    "no_match_indices = data_X2[data_X2.match == 0].index\n",
    "random_indices = np.random.choice(no_match_indices,no_match, replace=False)\n",
    "match_indices = data_X2[data_X2.match == 1].index\n",
    "under_sample_indices = np.concatenate([match_indices,random_indices])\n",
    "under_sample = data_X2.loc[under_sample_indices]\n",
    "X_under = under_sample.loc[:,under_sample.columns != 'match']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features = under_sample.iloc[:,0:63]\n",
    "label = under_sample['match']\n",
    "\n",
    "# your code goes here\n",
    "\n",
    "# Normalize Features \n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation and n_neighbors.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a PCA\n",
    "pca = PCA()\n",
    "\n",
    "#create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#create a pipeline that does a PCA and a KNN\n",
    "pipe = Pipeline(steps=[('pca', pca), ('knn', knn)])\n",
    "\n",
    "#Set up the parameters you want to tune for each of your pipeline steps\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 64)), #find how many principal componenet to keep\n",
    "    'knn__n_neighbors': list(range(1, 30)),  #find the best value of k\n",
    "}\n",
    "\n",
    "# your code goes here:\n",
    "# pass the pipeline and the parameters into a GridSearchCV with a 5-fold cross validation\n",
    "# call fit() on the GridSearchCV and pass in the normalized data (X_values, Y_values)\n",
    "# print out the best_score_ and best_params_ from the GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, iid=False)\n",
    "grid_search.fit(normalized_features, label)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation and n_neighbors.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a PCA\n",
    "pca = PCA()\n",
    "\n",
    "#create a KNN classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "#create a pipeline that does a PCA and a KNN\n",
    "pipe = Pipeline(steps=[('pca', pca), ('clf', clf)])\n",
    "\n",
    "#Set up the parameters you want to tune for each of your pipeline steps\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 64)), \n",
    "    \"clf__criterion\" : ['gini', 'entropy'],\n",
    "    \"clf__max_depth\": [5,10,15,20], \n",
    "    \"clf__min_samples_leaf\": [5,10,15,20]\n",
    "}\n",
    "\n",
    "# your code goes here:\n",
    "# pass the pipeline and the parameters into a GridSearchCV with a 5-fold cross validation\n",
    "# call fit() on the GridSearchCV and pass in the normalized data (X_values, Y_values)\n",
    "# print out the best_score_ and best_params_ from the GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, iid=False)\n",
    "grid_search.fit(features, label)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "# Desired Parameters\n",
    "params = {\"criterion\" : ['gini', 'entropy'],\n",
    "          \"max_depth\": [5,10,15,20], \n",
    "         \"min_samples_leaf\": [5,10,15,20],\n",
    "         \"max_features\": [5,10,15,20]}\n",
    "\n",
    "# Test Parameters\n",
    "grid_search = GridSearchCV(clf, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(features, label)\n",
    "\n",
    "# Print Results\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features = under_sample.iloc[:,0:63]\n",
    "label = under_sample['match']\n",
    "\n",
    "\n",
    "# Normalize Features \n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "# Desired Parameters\n",
    "x = list(range(1, 31))\n",
    "params = {\"n_neighbors\": x}\n",
    "\n",
    "# Test Parameters\n",
    "grid_search = GridSearchCV(neigh, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(normalized_features, label)\n",
    "\n",
    "# Print Results\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
